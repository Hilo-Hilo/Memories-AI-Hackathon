# Global Multi-Modal Hackathon

This document outlines the details of the Global Multi-Modal Hackathon hosted by Memories.ai, from September 29th to October 23rd.

## Agenda

1.  Memories.ai Introduction
2.  Sponsor Overview
3.  Hackathon details (Schedule, Prizes, Resources)
4.  Q&A
5.  Sponsor Presentations
6.  Guest Speakers

## About Us

We are a U.S.-based AI tech company founded by core members from **Meta Ray-Ban and Llama**, pioneering the frontier of **multimodal AI assistants and smart hardware**. Backed by nearly **$10 million** in funding from top Silicon Valley investors, our team's technical expertise and vision have earned industry-wide recognition, positioning us as leaders in the AI revolution.

### In collaboration with:

*   **University Research Labs:** MIT, SFS, Stanford
*   **Company Research Labs:** OpenAI, Google, Samsung, J.P. Morgan

## Selected temporal computing publications by Shen et al

*   Gesture2Text: A Generalizable Decoder for Word-Gesture Keyboards in XR Through Trajectory Coarse Discretization and Pre-training
*   RingGesture: A Ring-Based Mid-Air Gesture Typing System Powered by a Deep-Learning Word Prediction Framework
*   Encode-Store-Retrieve: Augmenting Human Memory through Language Encoded Egocentric Perception
*   ST-Think: How Multimodal Large Language Models Reason About 4D Worlds from Ego-Centric Videos
*   Boosting Gesture Recognition with an Automatic Gesture Annotation Framework
*   Duo Streamers: A Streaming Gesture Recognition Framework
*   VideoMAP: Toward Scalable Mamba-based Video Autoregressive Pretraining



## Memories.ai's Large Visual Memory Model

As the pioneering Large Visual Memory Model, we are moving beyond time-constrained memory limitations, truly ushering in an era where AI begins to possess unlimited visual memory.

## The Visual Memory Layer

A single semantic layer makes all video assets searchable, reusable, and AI-ready — speeding up retrieval, enabling human-like reasoning on large scale video data lake.

*   **Compression Layer:** End-to-end video & multimodal compression. Reduces storage + bandwidth costs.
*   **Indexing Layer:** Multi-modal indexing (video, text, audio, image). Ultra-compact & accurate representations.
*   **Aggregation Layer:** Organizes indexed data into knowledge graph. Provides semantic context & relationships.
*   **Serving (Database) Layer:** Central data storage and access. Feeds applications, APIs, and agents.



## Use cases

### 1. AI Powered Multimodal Album

Help users manage, search, and understand photos and videos, turning life data into the memory of an intelligent assistant.

*   Large-Scale Video Understanding
*   Edge Multimodal Processing

### 2. Smarter Memories Smarter Living

Memories.ai turns your phone into a smart memory assistant.

*   **Life Recording and Q&A:** Semantic Search, Natural Language Queries
*   **Managing Family Photo Albums:** Temporal Memory, Contextual Management
*   **Health and Lifestyle Analysis:** Multi-Video Analysis, Recursive Updates
*   **Intelligent Search and Recall:** MAG-Augmented Edge Case Identification

### 3. Speak. Learn. Adapt. XR Built Around You

Tailor behaviors to users, environments, and preferences.

*   Voice Customization
*   Behavior Personalization
*   Continuous Learning
*   Environment Awareness

### 4. Driving Intelligence That Sees and Learns

*   **Multi-source video analysis:** Supports simultaneous input from multi-camera data and simulation videos.
*   **Recursive memory updates:** Continuously refines scene understanding as new driving situations occur.

### 5. The New Foundation for Robotic Intelligence

Memories.ai gives robots human-like memory for smarter actions.

*   Adaptive Sampling
*   Token Compression
*   Motion Detection
*   Caching
*   Context Engineering
*   Customized Model
*   Fine-tuned on egocentric videos
*   Temporal RL
*   Quantization
*   Customized Prompt

### 6. Video Intelligence & Media Marketing Platform

Empowering brands with video search, trend analysis, viral insights & brand safety.

*   Product matching
*   Meets Influence Standard
*   Influencers style matching

### 7. Intelligent Surveillance

Video Understanding Agent System that automatically detects slip and fall incidents and analyzes table turnover rate. This system leverages video data for **efficient event detection** and **operational metric tracking**.

### 8. AI-Powered Re-editing

From Script to Screen, AI Makes Every Step Faster, Smarter, and More Cost-Efficient: Enhancing efficiency across search, ideation, script-to-footage matching, and editing – while cutting costs significantly.



## Our Sponsors

*   **Runware:** [Runware.ai](http://Runware.ai) delivers the fastest AI image and video generation—up to 20×cheaper than running your own infrastructure or using other platforms. Get started with just one line of code via a simple, flexible API.
*   **Prolific:** [Prolific.com](http://Prolific.com) Delivers fast, reliable, high-quality human data so you can build AI that’s smarter, fairer, and more useful.
*   **HeyBoss.AI:** [Heyboss.ai](http://Heyboss.ai) Vibe code platform to create apps and websites by chatting with AI.
*   **hume.ai:** [Hume.ai](http://Hume.ai) Voice ai that will transform your product with quality and versatility.

## Prizes

*   **Grand Prize:** **$3,000 cash + API credits**, or a sponsored trip (up to $3,000 value) for your team to **San Francisco to meet with VCs**
*   **Second Prize:** $1,000 cash + platform credits
*   **Third Prize:** $500 cash + platform credits

### Category Awards ($250 each)

*   **Unity in Innovation ($250)** - Ultimate technical partnership partner’s synergy
*   **Best UX ($250)** - Ease of use, design, delight factor, accessibility
*   **Most Viral Build ($250)** - Publish it on your LinkedIn or X, and receive the most engagements (comments + repostst + likes)

### Judge’s Choices ($100 each)

*   Hume’s choice
*   Heyboss’ choice
*   Prolific’s choice
*   Runware’s choice



## Criterias

| Dimension | Weight | What judges look for (evidence to show) |
| :--- | :--- | :--- |
| Technical Soundness & Architecture | 20% | Clear system diagram; choice of models/tooling; latency & cost awareness; evals/ablation or load tests; clean repo & reproducibility. |
| Agentic Behavior & Autonomy | 20% | Goal decomposition, planning, tool use, self-correction, guardrails, logs showing multi-step reasoning and recovery from failure. |
| Memory Design & Personalization | 20% | Working episodic/semantic memory (e.g., vector + structured store); retrieval quality, aging/forgetting, privacy controls; demo that memory measurably improves outcomes. |
| Affective Intelligence & Human-Centered UX | 10% | Clear user value from affect signals; safety & bias mitigation notes; Contains theme of consent & transparency |
| Real-World Value & Use-Case Scope | 10% | Concrete user/job-to-be-done, domain depth, stakeholder fit, basic market sizing or ROI; feasibility beyond the demo. |
| Completeness & Reliability | 10% | End-to-end demo; graceful error handling; offline/edge cases; minimal “happy-path” hardcoding; setup instructions. |
| Innovation Mashup | 5% | Use 2+ technical partnership’s products in project; the more the merrier. |
| Creativity & Polish | 5% | Originality, elegance, and demo storytelling; UI clarity; docs/readme quality. |

## Submission

All teams must submit their projects in form of a GitHub Repo to the **#submissions** channel on Discord and include:

*   Full source code and documentation
*   Include a README with Project Overview (what you built, why it matters), Team Introduction (who you are, location, roles, fun fact optional), Key Features & Tech Stack, Sponsor Tools Used (and how they were integrated), Challenges & Learnings, Future Improvements / Next Steps
*   Demo Presentation Video: Present the content in the README + Demo of your product (2-4 minutes) in form of a downloadable file or YouTube link

## Schedule

| Sunday | Monday | Tuesday | Wednesday | Thursday | Friday | Saturday |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| | Sep 29th London Opening Ceremony | Sep 30th Recording Distribution | Oct 1st | Oct 2nd | Oct 3rd | Oct 4th Office Hour 9-11AM PT |
| Oct 7th | Oct 6th Office Hour 8-10 PM PT | Oct 7th | Oct 8th | Oct 9th | Oct 10th Mid project Check in | Oct 11th Office Hour 9-11AM PT |
| Oct 12th | Oct 13th Office Hour 8-10 PM PT | Oct 14th | Oct 15th | Oct 16th | Oct 17th | Oct 18th Office Hour 9-11AM PT |
| Oct 19th | Oct 20th Office Hour 8-10 PM PT | Oct 21st | Oct 22nd Submission Deadline: 9AM PT | Oct 23rd San Francisco Finale | Oct 24th | Oct 25th |

## Resources

*   **Get API Credits:** [https://forms.gle/XoRZPxWiQdkcPa757](https://forms.gle/XoRZPxWiQdkcPa757)
*   **Previous Project Ideas:** [https://steel-brownie-182.notion.site/Built-with-memories-ai-2668d9b83c5c80e582cdc0aa03521e80?pvs=74](https://steel-brownie-182.notion.site/Built-with-memories-ai-2668d9b83c5c80e582cdc0aa03521e80?pvs=74)
*   **For teammate search, office hours, tech assistance, join Discord:** [https://discord.com/invite/xBQZ6HBBP3](https://discord.com/invite/xBQZ6HBBP3)
*   **Memories.ai API:** [https://memories.ai/docs/](https://memories.ai/docs/)
*   **HeyBoss.ai Platform:** [https://heyboss.ai/](https://heyboss.ai/)
*   **Hume.ai API:** [https://www.hume.ai/blog/tutorials-hume-api](https://www.hume.ai/blog/tutorials-hume-api)
*   **Prolific Platform:** [https://www.prolific.com/](https://www.prolific.com/)
*   **Runware API:** [https://runware.ai/docs/en/getting-started/introduction](https://runware.ai/docs/en/getting-started/introduction)

## Sponsor Presentations

*   **Krishna Visvanathan**
    *   Co-founder & Partner at Crane Venture Partners

